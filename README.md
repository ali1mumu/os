# 操作系统

docsify serve os

## 一  os 概念
> 从用户角度，os是控制软件>；
> 从资源管理，os是分配资源器；
> os 在硬件之上，应用程序之下；

> os 内部组件，包括 CPU 调度器、物理内存管理、虚拟内存管理、文件系统管理、中断处理与设备驱动

> os 特征：
> + 并发（一段时间；并行：一个时间节点，多gpu）
> + 共享（“同时”访问，互斥共享）
> + 虚拟
> + 异步（走走停停）

## 二  物理内存

### 2.1 os 的启动
> BIOS: 基本 I/O处理系统  
> Bootloader: 加载 OS  

> os基本启动  
> ![os基本启动](物理内存\os基本启动方式.png "os基本启动方式")  

|概念|来源|含义|处理时间|响应|硬件处理|软件处理（os）|
|----|----|-----|-----|----|-----|----|
|**系统调用**|应用程序        |应用程序**主动**向os发出服务请求                |异步或同步|等待和持续|   |   |
|**异常**   |不良的应用程序|非法指令或其他坏的处理状态  （eg:内存出错）|同步|杀死或重新执行想不到的应用程序指令|  |（异常编号）1 保存现场；2 处理异常（杀死或重新执行异常指令）；3 恢复现场|
|**中断**   |外设                |来自不同的硬件设备的计时器和网络的中断       |异步|持续，对用户应用程序是透明的|设置中断标记（CPU初始化）（1 将内部外部事件设置中断标记；2 中断事件的ID）|（1 保存当前处理状态；2 中断服务程序处理；3 清除中断标记；4 恢复之前保存的处理）|


### 2.2 连续内存
> 计算机基本硬件结构  
![计算机基本硬件结构 ](物理内存\计算机基本硬件结构.png "计算机基本硬件结构")

> os内核  
![os内核 ](物理内存\os内核.png "os内核")

> 在os中管理内存的不同方法（实现高度依赖硬件：必须知道内存架构和 MMU（内存管理单元））  
* 程序重定位
* 分段
* 分页
* 虚拟内存
* 按需分页虚拟内存 等等

#### 2.2.1 地址空间
> 物理地址空间：硬件支持的地址空间  
> 逻辑地理空间:一个运行的程序所拥有的内存范围  
> 地址空间  
![地址空间](物理内存\地址空间.png "地址空间 ")

#### 2.2.2 连续内存分配
> 内存碎片问题：空闲内存不能利用、外部碎片（未使用）、内部碎片（使用） 
> 分配策略(首次适配、最优适配、最差适配)：较简单，直接，没有优劣之分，都会产生碎片

|分配策略|优势|劣势|原理|需求|
|----|----|----|----|----|  
|首次适配|简单|容易产生外碎片；不确定性|简单实现|按地址排序的空闲列表；分配需要寻找的合适分区；重分配需要检查，看是否可以合并相邻空闲分区|
|最优适配|当大部分分配是小尺寸时非常有效；比较简单|外部碎片；重分配慢；易产生很多没用的微小碎片|避免分割大空间块，最小化尾部碎片产生的尺寸|按尺寸排列的空间块列表；分配需要寻找的合适分区；重分配需搜索及合并相邻空闲分区|
|最差适配|假如分配是中等尺寸效果最佳|外部碎片；重分配慢；易于破碎大的空间块以至于大分区无法被分配|避免有太多微小碎片|尺寸排列的空间块列表；分配很快；重分配需合并相邻空闲分区，然后调整空闲块列表|

> 压缩式碎片整理：可通过挪动程序块，来得到较大空间块
* 重置程序以合并孔洞
* 要求所有程序是动态可重置的

> 表换式碎片整理：主存的程序移到磁盘中
* 运行程序需要更多内存
* 抢占等待的程序 & 回收他们内存

> 地址安全检查



> 连续内存分配的缺点
>
> * 分配给一个程序的物理内存是连续的
>
> * 内存利用率较低
>
> * 有外碎片、内碎片的问题

### 2.3 非连续内存
> 非连续分配的优点
>
> * 一个程序的物理地址空间是非连续的
> * 更好的内存利用和管理
> * 允许共享代码与数据（共享库等）
> * 支持动态加载和动态链接



非连续分配缺点:

>  建立虚拟地址和物理地址之间的转换

* 软件方案（开销大）
* 硬件方案（分段、分页、页表）



分段的硬件实现方案（运用较少）

![分段](物理内存\分段.png "分段")



>  分页
>
> * 划分物理内存至固定大小的帧 大小是2的幂
> * 划分逻辑地址空间至固定大小的页 大小是2的幂
> * 建立方案 转换逻辑地址为物理地址（页表或MMU/TLB）



帧 （物理）

![帧](物理内存\帧.png "帧")



 页(页内偏移大小是固定的)

![页](物理内存\页.png "页")



页寻址机制（页映射到帧；页是连续的虚拟内存；帧是非连续的物理内存；不是所有的页都有对应的帧）

![页寻址机制](物理内存\页寻址机制.png "页寻址机制")





页表（快表TLB、二级/多级页表、反向页表）

页表结构

![页表结构](物理内存\页表结构.png "页表结构")



>  分页机制的性能问题
>
> * 页表可能非常大
> * 效率问题（如果页表大，cpu放不下）
>
> 解决
>
> * 缓存
> * 间接访问



TLB（translation look-aside buffer）

![TLB](物理内存\TLB.png "TLB")



二级页表

多级页表

![多级页表](物理内存\多级页表.png "多级页表")



> 反向页表（1，2，3）
>
> 解决问题: 大地址空间问题 (有大地址空间，前向映射页表变得繁琐)
>
> 不是让页表与逻辑地址空间大小相对应，而是让页表与物理地址空间的大小相对应（逻辑/虚拟地址空间增长速度快于物理地址空间）
>
> 1 基于页寄存器的方案
>
> ![基于页寄存器的方案](物理内存\基于页寄存器的方案.png "基于页寄存器的方案")
>
> 优点：转换表的大小相对于物理内存来说很小; 转换表的大小跟逻辑地址空间的大小无关
>
> 缺点：需要的信息对调了，即根据帧号可找到页号;  如何转换回来？根据页号找到帧号;  在需要在反向页表中搜索想要的页号
>
> 2 基于关联内存的方案
>
> ![基于关联内存的方案](物理内存\基于关联内存的方案.png "基于关联内存的方案")
>
> 3 基于哈希查找的方案



### 2.4   虚拟内存

虚拟内存出现之前是覆盖技术和交换技术



> 覆盖技术
>
> ![覆盖技术](物理内存\覆盖技术.png "覆盖技术")
>
> 缺点：编程员确定覆盖关系，费时费力，增加编程难度；时间延长换取空间节省



> 交换技术
>
> ![交换技术](物理内存\交换技术.png "交换技术")
>
> ![交换技术2](物理内存\交换技术2.png "交换技术2")
>
> 缺点：以进程为交换的单位，需要把进程的整个地址空间都换进换出，增加处理器的开销



> 虚拟技术
>
> 目标：内存不够用的情形
>
> 程序的局部性原理：程序在执行过程中一个较短时期，所执行的指令地址和指令的查找数地址，分别局限于一定区域。 
>
> 虚拟技术在页式或段式内存管理的基础上实现
>
> 虚拟技术的基本特征：大的用户空间；部分交换；不连续性
>
> 虚拟页式内存管理(大部分；增加请求调页和页面置换功能)
>
> ![虚拟页式内存管理](物理内存\虚拟页式内存管理.png "虚拟页式内存管理")
>
> 页表表项
>
> ![页表表项](物理内存\页表表项.png "页表表项")
>
>  缺页中断
>
> ![缺页中断](物理内存\缺页中断.png "缺页中断")
>
> 保存未被映射的页：能够简单地识别在二级存储器的页；交换空间（磁盘或文件）
>
> 后备存储：
>
> * 一个虚拟地址空间的页面可以被映射到一个文件中的某个位置
> * 代码段：映射到可执行二进制文件
> * 动态加载的共享库程序段：映射到动态调用的库文件
> * 其他段：可能被映射到交换文件



> 虚拟内存性能
>
> * 有效存储器访问时间（EAT）：EAT=访问时间*页表命中几率+ page fault 处理时间 * page fault 几率
>
>   



### 2.5 虚拟内存相关算法（页面置换算法）

> 页面置换算法分为局部页面置换算法和全局页面置换算法
>
> 功能：当缺页中断发生，需要调入新的页面而内存已满时，选择内存当中哪个物理页面被置换
>
> 目标：**尽可能地减少页面的换进换出次数**
>
> **页面锁定**；实现方法：在页表中添加锁定标志位
>
> 局部页面置换算法：
>
> * 最优页面置换算法 (OPT )
> * 先进先出算法 (FIFO)
> * 最近最久未使用算法 (LRU)
> * 时钟页面置换算法 (Clock)
> * 最不常用算法 (LFU)
> * Belady现象
> * LRU、FIFO和Clock的比较
>
> 全局页面置换算法
>
> * 工作集模型
> * 工作集页置换算法
> * 缺页率置换算法



#### 2.5.1 局部页面置换算法



| 算法                      | 基本思路                                                     | 优点                         | 缺点                                                         |
| ------------------------- | ------------------------------------------------------------ | ---------------------------- | ------------------------------------------------------------ |
| 最优页面置换算法 (OPT )   | 当一个缺页中断发生时，对于保存在内存当中的每一个逻辑页面，计算在它的下一次访问之前，还需等待多久时间，从中选择等待时间最长的哪个，作为被置换的页面 | 可作为其他算法的性能评价指标 | 这是理想情况，实际系统无法实现                               |
| 先进先出算法 (FIFO )      | 选择在内存中驻留时间最长的页面并淘汰（系统维护着一个链表、记录所有位于内存当中的逻辑页面） | 简单实现                     | 性能较差，调出页面可能是经常访问的页面，有**belady现象**，很少单独使用 |
| 最近最久未使用算法 (LRU)  | 当一个缺页中断发生时，选择最久未使用的哪个页面并淘汰（依据是程序的局部性原理）（时间） | 效果一般                     | 需要记录各个页面使用时间的先后顺序，**开销较大**。实现：链表、堆栈 |
| 时钟页面置换算法（clock） | * 需要用到页表当中的访问位，当一个页面被装入内存时，把该位初始化为0，如何如果这个页面被访问（读 / 写），则该位置为1；* 把各个页面组织成环形链表，把指针指向最老的页面；* 当一个缺页中断发生时，考察指针所指向的最老页面，若访问位为0，立即淘汰，若访问位为1，则该位置为0，然后指针往下移动一格。如此下去，直到找到被淘汰的页面，然后把指针移动到它的下一格 |                              |                                                              |
| 二次机会法                | 修改clock算法，使它允许脏页总是在一次时钟头扫描中保留下来；同时使用脏位和使用位来指导换置 |                              |                                                              |
| 最不常用算法（LFU）       | 当一个缺页中断发生时，选择访问次数最少的哪个页面，并淘汰（每个页面设置访问计数器，访问一次，加1）（次数或频率） |                              | 开销大（使用寄存器）                                         |

> **Belady现象**: 在采用FIFO算法时，有时会出现分配的物理页面数增加，缺页率反而提高的异常现象**Belady现象的原因**：FIFO算法的置换特征与进程访问内存的动态特征是矛盾的，与置换算法的目标不一致



> 局部页面置换算法问题



> **局部性原理**是页面置换算法的前提。
>
> **常驻集**是在当前时刻，进场时机驻留在内存当中的页面集合



#### 2.5.2 全局页面置换算法

>  工作集模型
>
> ![工作集](物理内存\工作集.png "工作集")
>
> 追踪之前 \tau 个的引用在之前 \tau 个内存访问的页引用是工作集，\tau 被称为窗口大小。



> 缺页率页面置换算法
>
> **可变分配策略**：常驻集大小可变
>
> * 可采用**全局页面置换**方法
> * 优缺点：性能较好，但增加了系统开销
> * 具体实现：可以使用**缺页率算法**（PFF）来动态调整常驻集大小



> 缺页率："缺页次数"/"内存访问次数" 或"缺页的平均时间间隔的倒数"
>
> 影响缺页率的因素：页面置换算法；分配给进度的物理页面数目；页面本身的大小；程序的编写方法



> 一个交替的工作集计算明确的试图最小化页缺失
>
> * 当缺页率高的时候，增加工作集
> * 当缺页率低的时候，减少工作集



> 频繁地内存与外存之间替换页面，从而使进程运行速度变得很慢，称为”**抖动**“
>
> 评价指标：平均页缺失时间；内存大小
>
> 抖动问题可能会被本地页面置换改善

## 三  进程

### 3.1 进程的概念

> 进程：一个具有一定独立功能的程序在一个数据集合上的一次动态执行过程



> 一个进程一个包括：
>
> * 程序的代码
> * 程序处理的数据
> * 程序计数器的值，指示下一条将运行的指令
> * 一组统一的寄存器的当前值、堆、栈
> * 一组系统资源
>
> 进程包含了正在运行的一个程序的所有状态信息



> 进程与程序的关系
>
> * 程序是产生进程的基础
> * 程序的每次运行构成不同的进程
> * 进程是程序功能的体现
> * 通过多次执行，一个程序可对应多个进程；通过调用关系，一个进程可包含多个程序
>
> 进程与程序的区别
>
> * 进程是动态的，程序是静态的：程序是有序代码的集合；进程是程序的执行。进程有核心态/用户态
> * 进程是暂时的，程序是永久的
> * 进程与程序的组成不同：进程的组成包括程序、数据和进程控制块(即进程状态信息）



> 进程的特点
>
> * 动态性：可动态地创建、结束进程
> * 并发性：进程可以被独立调度并占用处理机运行，**并发并行**（并行需多GPU）
> * 独立性：不同进程的工作不相互影响
> * 制约性：因访问共享数据/资源或进程间同步而产生制约
>



> 描述进程的数据结构：进程控制块（PCB）
>
> os为每个进程都维护了一个PCB，用来保存与该进程有关的各种状态信息。
>
> PCB是进程存在的唯一标志
>
> PCB含有三大类信息：
>
> * 进程标识信息。如本进程的标识，本进程的生产者标识；用户标识
> * 处理机状态信息保存区
> * * 用户可见寄存器
>   * 控制和状态寄存器
>   * 栈指针
> * 进程控制信息
> * * 调度和状态信息
>   * 进程间通信信息
>   * 存储管理信息
>   * 进程所用资源
>   * 有关数据结构连接信息



### 3.2 进程管理

> 进程的生命期管理
>
> * 进程创建（事件：系统初始化时；用户请求创建一个新进程；正在运行的进程执行了创建进程的系统调用）
> * 进程运行
> * 进程等待
> * * 以下情况时等待：请求并等待系统服务，无法马上完成；启动某种操作，无法马上完成；需要的数据没有到达
> * * 进程只能自己阻塞自己
> * 进程唤醒
> * * 原因：被阻塞进程需要的资源可被满足；被阻塞进程等待的事件到达；将该进程的PCB插入到就绪队列
>   * 进程只能被别的进程或操作系统唤醒
> * 进程结束
> * * 正常退出（自愿）
>   * 错误退出（自愿）
>   * 致命错误（强制性）
>   * 被其他进程所杀（强制性）



> 进程状态变化模型
>
> 进程的三种基本状态：进程在生命结束倩处于且仅处于三种基本状态之一
>
> * 运行状态（Running）
> * 就绪状态(Ready)
> * 等待状态（阻塞状态bolcked）
>
> 进程其它的基本状态：
>
> * 创建状态（New)
> * 结束状态（Exit）
>
> 状态变化图
>
> ![状态变化图](进程\状态变化图.png "状态变化图")
>
> 可能的状态变化如下：
>
> NULL—New：一个新进程被产生出来执行一个程序
>
> New—Ready：当进程被创建完成并初始化后，一切就绪准备运行时，变为就绪状态



> 进程挂起
>
> 进程在挂起状态时，意味着进程没有占用内存空间。处于挂起状态的进程映像在磁盘上。
>
> ![挂起](进程\挂起.png "挂起")
>
> 挂起状态：
>
> * 阻塞挂起状态（Blocked-suspend）：进程在外存并等待某事件出现
> * 就绪挂起状态（Ready-suspend）：进程在外存，但只要进入内存，即可运行
>
> 挂起：把一个进程从内存转到外存
>
> * 阻塞到阻塞挂起
> * 就绪到就绪挂起
> * 运行到就绪挂起
>
> 在外存时状态转换
>
> * 阻塞挂起到就绪挂起
>
> 解挂/激活：把一个进程从外存转到内存
>
> * 就绪挂起到就绪
> * 阻塞挂起到阻塞



> 状态队列
>
> 由os来维护一组队列，用来表示系统当中所有进程的当前状态
>
> 不同的状态分别用不同的队列来表示
>
> 每个进程的PCB都根据它的状态加入到相应的队列中，当一个进程的状态发生变化时，它的PCB从一个状态队列中脱离出来，加入到另外一个队列
>
> ![状态表示方法](进程\状态表示方法.png "状态表示方法")
>
> 

### 3.3 线程

> 线程=进程-共享资源
>
> 线程优点：
>
> * 一个进程可以存在多个线程
> * 各个线程之间可以并发地执行
> * 各个线程之间可以共享地址空间和文件等资源
>
> 线程的缺点：一个线程崩溃，会导致其所属进程的所有线程崩溃



> 线程与进程的比较
>
> * 进程是资源分配单元，线程是CPU调度单位
> * 进程拥有一个完整的资源平台，而线程只独享必不可少的资源。如寄存器和栈
> * 线程同样具有就绪、阻塞和执行三种基本状态，同样具有状态之间的转换关系
> * 线程能减少并发执行的时间和空间开销
> * * 线程的创建时间比进程短
>   * 线程的终止时间比进程短
>   * 统一进程内的线程切换时间比进程短
>   * 由于统一进程的各线程共享内存和文件资源，可直接进行不通过内核通信



> 线程的实现
>
> | 实现方式   | 实现地址                 | 系统                                            | 概念                                                         | 缺点                                                         |
> | ---------- | ------------------------ | ----------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
> | 用户线程   | 在用户空间实现           | POSIX Pthreads, Mach C-threads, Solaris threads | 在用户空间实现的线程机制，它不依赖于os的内核，有一组用户及的线程库函数来完成线程的管理，包括进程的创建、终止、同步和调度等。 | 阻塞性的系统调用如何实现？如果一个线程发起系统调用而阻塞，则整个进程在等待； 当一个进程开始运行后，除非它主动递交出CPU的使用权，否则它所在的进程当中的其他线程将无法运行； 由于时间片分配给进程，故与其他进程比，在多线程执行时，每个线程得到的时间片较少，执行回较慢 |
> | 内核线程   | 在内核实现               | Windows，Solaris，Linux                         | 指在os的内核实现的一种线程机制，由os的内核来完成线程的创建、终止和管理 | 系统开销较大                                                 |
> | 轻量级进程 | 在内核实现，支持用户线程 | Solaris/Linux                                   | 是内核支持的用户线程。一个进程可有一个或多个轻量级进程，每个量级进程由一个单独的内核线程来支持 |                                                              |
>
> 用户线程与内核线程的对应关系：多对一；一对一；多对多



### 3.4 进程控制

> 上下文切换(一般是硬件)
>
> 停止当前运行进程（从运行状态改变其他状态）并且调度其他进程（转变成运行状态）
>
> * 必须在切换之前存储许多部分的进程的上下文
> * 必须能够在之后恢复透明，所以进程不能显示它曾经被暂停过
> * 必须快速（上下文转换时非常频繁）
>
> 存储什么上下文？
>
> * 寄存器（PC，SP...）CPU 状态，...
> * 一些时候可能会费时，所以尽可能避免
>
> ![上下文](进程\上下文调换.png "上下文调换")
>
> os为活跃进程准备了进程控制块PCB
>
> os将进程控制块放置在一个合适的队列里：就绪队列；等待I/O队列；僵尸队列



> 系统调用exec( )加载程序取代当前运行的进程
>
> Exec（） 调用运行一个进程“加载”一个不同的程序且在main开始执行（事实上 _start）
>
> Exec（） 允许一个进程指定参数的数量（arge）和它字符串参数数组（argv）;代码，stack(栈)和heap(堆)重写
>



> fork( ) 的简单实现
>
> * 对子进程分配内存
> * 复制父进行的内存和CPU寄存器到子进程里
> * 开销昂贵
>
> 在99%情况下，调用fork( ) 后调用exec( )
>
> * 在fork( ) 操作中内存复制是没有作用的
> * 子进程将可能关闭打开的文件和连接
> * 开销高
>
> vfork( ) （轻量级fork( ) ）
>
> * 一个创建进程的系统调用，不需要创建一个同样的内存映像
> * 子进程应该立即调用exec( )



> wait( ) 系统调用是被父进程用来等待子进程的结束
>
> * 一个子进程向父进程返回一个值，所以父进程必须接受这个值并处理
> * wait( )系统调用作用
> * * 使父进程区睡眠来等待子进程的结果
>   * 当子进程调用wait( ) 的时候，os解锁父进程，且将通过exec()传递得到的返回值作为wait调用的结果（连同子进程的pid）如果没有子进程存活，wait( )立即返回
>   * 若有为父进程的僵尸等待，wait( )立即返回其中一个值（并解除僵尸状态）



> 进程结束执行后，调用exit( )
>
> 系统调用
>
> * 将这程序的“结果”作为一个参数
> * 关闭所有打开的文件、连接等等
> * 释放内存
> * 释放大部分支持进程的os结构
> * 检测是否父进程是存活的
> * 清理所有等待的僵尸进程
>
> 进程终止是最终的垃圾收集（资源回收）



![进程控制](进程\进程控制.png "进程控制")



## 五  调度

> CPU调度
>
> * 从就绪队列中挑选一个进程/线程作为CPU将要运行的下一个进程/线程
> * 调度程序：调选进程/线程的内核函数（通过一些调度策略）



> 内核运行调度程序的条件（满足一条即可）
>
> * 一个进程从运行状态切换到等待状态
> * 一个进程被终结了
>
> 不可抢占
>
> * 调度程序必须等待事件结束
>
> 可以抢占
>
> * 调度程序在中断被响应后执行
> * 当前进程从运行切换到就绪，或者一个进程从等待切换到就绪
> * 当前运行的进程可以被换出



### 5.1 调度原则

> 执行模型：程序在CPU突发和I/O中交替
>
> * 每个调度决定都是关于在下一个CPU突发时将哪个工作交给CPU
> * 在事件分片机制下，线程可能在结束当前CPU突发前被迫放弃CPU



> 评价指标
>
> * CPU使用率：CPU处于忙状态所占时间的百分比
> * 吞吐量：在单位时间内完成的进程数量
> * 周转时间：一个进程从初始化到结束，包括所有等待时间所花费的时间（周转时间=等待时间+服务时间）
> * 等待时间：进程在就绪队列中的总时间
> * 响应时间：从一个请求被提交到产生第一次相应所花费的总时间 



> 更好：传输文件时**高带宽**；玩游戏时的**低延迟**。这两个因素是**独立**的
>
> * 减少响应时间
> * 减少平均响应时间的波动
> * 增加吞吐量：减少开销；系统资源的高效利用
> * 减少等待时间
> * 低延迟调度增加了交互式表现
> * os需要保证吞吐量不受影响
> * 吞吐量是os的计算带宽
> * 响应时间是os的计算延迟
> * 公平通常会增加平均响应时间



### 5.2 调度算法

| 简称                       | 算法                                   | 定义                                                         | 优                     | 缺点                                                         | 注意事项                         |
| -------------------------- | -------------------------------------- | ------------------------------------------------------------ | ---------------------- | ------------------------------------------------------------ | -------------------------------- |
| FCFS                       | 先来先服务                             | FIFO队列的规定：如果进程在执行中阻塞，队列中的下一个会得到CPU | 简单                   | 平均等待时间波动较大；花费时间少的任务可能排在花费时间长的任务后；可能导致I/O和CPU之间的重叠处理（CPU密集型进程会导致I/O设备闲置时，I/O密集型进程也在等待） |                                  |
| SPN(SJF) SRT               | 短进程优先（短作业优先）短剩余时间优先 | 按照预测的完成时间来将任务入队；可以是可抢占的或不可抢占的   | 最优平均等待时间       | 可能导致饥饿（连续的短任务流回使长任务饥饿；短任务可用时的任何长任务的CPU时间都会增加平均等待时间）；需要预知未来 |                                  |
| HRRN                       | 最高响应优先                           | R=（w+s）/s: w 等待时间，s 执行时间；不可抢占；关注进程等待了多久时间；在SPN上改进 |                        |                                                              |                                  |
| Round Robin                | 轮循                                   | 再叫作量子（或时间切片）的离散单元中分配处理器；时间片结束时，切换到下一个准备好的进程；目标：选择合适的时间量子（**经验：维持上下文切换开销处于1% 以内**） | 公平，但平均等待时间长 | RR花销：额外的上下文切换；时间量子太大（等待时间过长；极限情况退化为FCFS）；时间量子小（吞吐量由于大量的上下文切换开销受到影响） | 使用时间切片和抢占来轮流执行任务 |
| Multilevel Feedback Queues | 多级反馈队列                           |                                                              |                        |                                                              | 优先级队列中的轮循               |
| Fair Share Scheduling      | 公平共享调度                           |                                                              |                        |                                                              |                                  |



### 5.3 实时调度

> 定义：正确性依赖于其**时间和功能**两方面的一种os
>
> 性能指标：**时间约束的及时性**；速度和平均性能相对不重要
>
> 主要特性：时间约束的可预测性
>
> 分为：强实时系统（在保证时间内必须完成重要任务）和弱实时系统（尽量完成）
>
> 任务（工作单元）：一次计算、一次文件读取 ...
>
> 属性：取得进展所需要的资源；定时参数
>
> 硬时限
>
> * 如果错过最后期限，可能回发生灾难性或非常严重的后果
> * 必须验证，**保证确定性**
>
> 软时限
>
> * 理想情况下，时限应该被最大满足。如果优时限没有满足，则可降低要求
> * 尽最大努力区保证
>
> 表示一个实时系统是否能够满足deadline要求
>
> * 决定实时任务执行的顺序
> * 静态优先级调度
> * 动态优先级调度
>
> RM速率单调调度
>
> * 最佳静态优先级调度
> * 通过**周期**安排优先级
> * 周期越短优先级越高
> * 执行周期最短的任务
>
> EDF最早期限调度
>
> * 最佳的动态优先级调度
> * deadline 越早优先级越高
> * 执行deadline最早的任务



### 5.4 多处理器调度

> 优点：负载共享
>
> 缺点：CPU调度更加复杂



> 对称多处理器
>
> * 每个处理器运行主机的调度程序
> * 需要在调度程序中同步



> 可以发生在任何基于优先级的可抢占的调度机制中
>
> 优先级反转的持续时间取决于其他不想关任务的不可预测的行为
>
> 低优先级任务继承高优先级任务的优先级依赖于共享的资源



## 六 协同多道程序设计和并发问题

### 6.1 临界区

> 独立的线程：
>
> * 不和其他线程共享资源或状态
> * **确定性**：输入状态决定结果
> * **可重视**：能够重现起始条件，I/O
> * 调度顺序不重要
>
> 合作线程：
>
> * 在多个线程中共享状态
> * 不确定性
> * 不可重现
>
> 不确定性和不可重现意味着bug可能是间歇性发生的
>
> 进程/线程合作优点
>
> * 共享资源
> * 加速
> * 模块化



> 竞态条件 Race condition
>
> * 系统缺陷：结果依赖于并发执行或事件的顺序/时间（不确定性，不可重现）
> * 避免竞态：指令不被打断



> 原子操作 atomic operation
>
> * 原子操作是指一次不存在任何中断或者失败的执行
> * 实际上操作往往不是原子的



> 临界区：进程中的一段需要访问共享资源并且当另一个进程处于相应代码区域时便不会被执行的代码区域
>
> 互斥：当一个进程处于临界区并访问共享资源时，没有其他进程会处于临界区并且访问任何相同的共享资源
>
> 死锁：两个或以上的进程，在相互等待完成特定任务，而最终没法将自身任务进行下去
>
> 饥饿：一个可执行的进程，被调度器持续忽略，以至于虽然处于可执行状态却不被执行
>
> 锁：
>
> 解锁：



> 临界区特征：
>
> * 互斥：同一时间临界区中最多存在一个线程
> * progress：如果一个线程想进入临界区，那么它最终会成功
> * 有线等待：如果一个线程 i 处于入口处，那么在 i 的请求被接受之前，其他线程进入临界区的时间是有限制的
> * 无忙等待（可选）：如果一个进程在等待进入临界区，那么在它可以进入之前会被挂起
>
> 对临界区的保护方法：禁用硬件中断；基于软件的解决方案；更高级的抽象



> 禁用硬件中断（小心使用）
>
> * 没有中断，没有上下文切换，因此没有并发
> * 进入临界区：禁用中断
> * 离开临界区：开启中断
> * 一旦中断被禁用，线程就无法被停止（整个系统会停；可能导致其他线程处于饥饿状态）
> * 若临界区可以任意长，则无法限制响应中断所需时间（可能存在硬件问题）



> 基于软件的解决方案
>
> * Dekker 算法：双线程的临界区问题
>
> * bakery算法：n 线程的临界区问题
> * 复杂：需要两个进程间的共享数据项
> * 需要忙等待：浪费CPU时间
> * 没有硬件保证的情况下无真正的软件解决方案（需要原子的LOAD和STORE指令）



> 更高级的抽象
>
> 锁是一个抽象的数据结构
>
> * 二进制状态（锁定/解锁），两种方法
> * Lock: Acquire() 锁被释放前一直等待，然后得到锁
> * Lock: Release() 释放锁，唤醒任何等待的进程
> * 互斥可以使用锁来顺序（需要硬件支持）
>
> 使用锁来编写临界区
>
> Teat - and - Set测试和置位（机器指令）
>
> *  从内存中读取值
> * 测试该值是否位1（然后返回真或假）
> * 内存值设置为1
>
> 交换：交换内存中的两个值
>
> 优点：
>
> * 适用于单处理器或共享主存的多处理器中任意数量的进程
> * 简单且容易证明
> * 可以用于支持多临界区
>
> 缺点：
>
> * 忙等待消耗处理器时间
> * 当进程离开临界区且多个进程在等待的时候可能导致饥饿
> * 死锁：如果一个低优先级的进程拥有临界区且一个高优先级进程页需求，那么高优先级进程会获得处理器并等待临界区



### 6.2 信号量

> 抽象数据类型
>
> * 一个整型（sem），两个原子操作
> * P() : sem 减1 ，如果sem<0, 等待，否则继续
> * V() : sem 加1 ，如果sem<=0, 唤醒一个等待的P



> 信号量是**整数**
>
> 信号量是**被保护**的变量
>
> * 初始化完成后，唯一改变一个信号量的值的办法是通过P( )和V( )
> * 操作必须是原子
>
> P( )**能够阻塞**，V( )不会阻塞
>
> 两种类型的信号量
>
> * 二进制信号量：可以是0或1
> * 一般/计数信号量：看取任意值
> * 两者相互表现（给定一个可以实现另一个）
>
> 信号量可以用在2个方面
>
> * 互斥
> * 条件同步（调度约束：一个线程等待另一个线程的事情发生）
>
> 正确性要求：
>
> * 在任何一个时间只能由一个线程操作缓冲区（互斥）
> * 在缓冲区为空，消费者必须等待生产者（调度/同步约束）
> * 当缓冲区满，生产者必须等待消费者（调度/同步约束）
>
> 每个约束用一个单独的信号量
>
> * 二进制信号量互斥
> * 一般信号量fullBuffers
> * 一般信号量emptyBuffers



> 信号量实现
>
> * 信号量的双用途：互斥和条件同步；单等待条件是独立的互斥
> * 读/开发代码比较困难
> * 容易出错：使用信号量已经被另一个线程占用；忘记释放信号量
> * 不能够处理死锁问题



#### 6.2.1 管程

> 目的：分离互斥和条件同步的关注
>
> 管程的定义：
>
> * 一个锁：指定临界区
> * 0或多个条件变量：等待/通知信号量用于管理并发访问共享数据
>
> 一般方法：
>
> * 收集在对象/模块中的相关共享数据
> * 定义方法来访问共享数据
>
> 条件变量
>
> * 允许等待状态进入临界区
> * * 允许处于等待（睡眠）的线程进入临界区
>   * 某个时刻原子释放锁进入睡眠
> * wait( ) :释放锁，睡眠，重新获得锁返回后
> * signal( )(broadcast( ))：唤醒等待者（或所有等待者），如果有
> * 实现：
> * * 需要维护每个条件队列
>   * 线程等待的条件等待signal( )
> * 开发/调试并行程序难：非确定性的交叉指令
> * 同步结构
> * * 锁：互斥
>   * 条件变量：有条件同步
>   * 其他原语：信号量
> * ![管程](同步问题\管程.png "管程")



#### 6.2.2 经典同步问题

> **读者-写者问题**
>
> 动机：共享数据的访问
>
> 两种类型使用者：
>
> * 读者，不需要修改数据，只读数据集；透明不执行任何更新，读者优先
> * 写者：读取和修改数据，可以读取和写入
>
> 问题的约束：
>
> * 允许同一时间有多个读者，单在任何时候只有一个写者
> * 当没有写者是读者才能访问数据
> * 当没有读者和写者时，写者才能访问数据
> * 在任何时候只能有一个线程可以操作共享数据
>
> 共享数据
>
> * 数据集
> * 信号量 CountMutex 初始化为1
> * 信号量 WriteMutex 初始化为1
> * 整数 Rcount 初始化为0

**P70   5：00-P75，P81 未看**



### 6.3 死锁

> 死锁的定义：一组阻塞的进程有一种资源等待获取另一个进程所占有的一个资源
>
> 如果图中不包括循环，则没有死锁
>
> 如果图中包括循环，则
>
> * 如果每个资源类只有一个实例，则死锁
> * 如果每个资源类有几个实例，可能死锁



> 死锁特征：
>
> * 互斥：在同一时间只能有一个进程使用资源
> * 持有并等待：进程保持至少一个资源正在等待获取其他进程持有额外资源
> * 无抢占：一个资源只能被进程自愿释放，进程已经完成任务之后
> * 循环等待
>
> 死锁处理办法
>
> * 死锁预防
> * 死锁避免
> * 死锁检测
> * 死锁恢复
>
> 确保系统永远不进入死锁状态
>
> 运行系统进入死锁状态，任何恢复
>
> 忽略死锁问题，假装系统从来没发生死锁，用于大多数os，包括UNIX



> 死锁预防：限制申请方式
>
> * 互斥：共享资源不是必须的，必须占用非共享资源
>
> * 占用并等待：必须保证当一个进程请求的资源，它不持有任何其他资源
> * 无抢占
> * 循环等待：对所有资源类型进行排序，并要求每个进程按照资源顺序进行申请



> 死锁避免：**需要系统具有一些额外的先验信息提供**
>
> * 最简单和最有效的模式是要求每个进程声明它可能需要的每个类型资源的**最大数目**
> * 资源的分配状态是通过限定**提供与分配**的资源数量，和进程的**最大**需求
> * 死锁避免算法**动态检查**的资源状态，以确保永远不会有一个环形等待状态
>
> * 系统处于安全状态：针对所有进程，存在安全序列
> * 一个进程请求可用资源，系统必须判断立即分配是否能使系统处于安全状态



> 死锁检测：允许系统进入死锁状态
>
> 死锁检测算法：算法开销大



> 死锁恢复
>
> * 终止所有的死锁进程
> * 在一个时间内终止一个进程指导死锁消除
> * 终止进程的顺序应该是
> * * 进程的优先级
>   * 进程运行时间
>   * 进程占用的资源
>   * 进程完成需要的资源
>   * 多少进程需要被终止
>   * 进程是交互还是批处理
> * 选择一个受害者-最小的成本
> * 回滚-返回一些安全状态，重启进程到安全状态



### 6.4 IPC 进程通信

> IPC 提供两个操作：
>
> * send(P，message)  : 消息大小固定或可变，发送消息到进程P
> * receive( Q，message )：从进程Q接受消息
>
> 消息传递可以是阻塞或非阻塞
>
> 阻塞被认为是同步的，非阻塞是异步的



> 直接通信
>
> * 进程必须正确的命名对方
> * 通信链路的属性：自动建立链路；一条链路对应一对通信进程；每队进程间只有一个链路存在；链路可以单向，但一般双向

> 间接通信
>
> * 定向从消息队列接收消息
> * * 每个消息队列有一个唯一的ID
>   * 只有他们共享一个消息队列，进程才能够通信
> * 通信链路的属性
> * * 只有进程共享一个共同的消息队列，才建立链路
>   * 链接可以与许多进程相关联
>   * 每对进程可以共享多个通信链路
>   * 连接可以是单向或双向
> * 操作
> * * 创建一个新的消息队列
>   * 通过消息队列发送和接收消息
>   * 销毁消息队列
> * 原语定义：
> * * send(A，message)  : 发送消息到队列A
> * * receive( A，message )：从队列A接受消息



> 队列的消息被附加到链路，3种方法：
>
> * 0容量：发送方必须等待接收方
> * 有限容量：如果队列满，发送方必须等待接收方
> * 无限容量：发送方不需要等待



#### 6.4.1 信号

> 软件中断通知事件处理（效率高）
>
> 接收消息会发生：
>
> * Catch：指定信号处理函数被调用
> * Ignore：依靠os的默认操作
> * Mask：闭塞信号因此不会传送
>
> 不足：不能传输要交换的任何数据



#### 6.4.2 管道(古老)

> 子进程从父进程继承文件描述符
>
> 进程不知道从键盘、文件、程序读取或写入到终端，文件，程序
>
> 管道有限



#### 6.4.3 消息队列

> 消息队列按FIFO来管理消息
>
> message作为一个字节序列存储
>
> message queues 消息队列

#### 6.4.4 共享内存（最快，没有系统调用干预）

> 进程
>
> * 每个进程都有私有地址空间
> * 在每个地址空间内，设置共享内存段
>
> 优点：快速、方便地共享数据
>
> 不足：必须同步数据访问



## 七 文件系统

### 7.1 基本概念

> 文件系统：一种用于持久性存储的系统抽象
>
> * 在存储器上：组织、控制、导航、访问和检索数据
> * 大多数计算机系统包含文件系统
>
> 文件：文件系统中的一个单元的相关数据在os中的抽象

> 分配文件磁盘空间：管理文件块；管理空闲空间；分配算法
>
> 管理文件集合：
>
> * 定位文件及其内容
> * 命名：文件接口
> * 最常见：分层文件系统
> * 文件系统类型
>
> 提供的便利及特征
>
> * 保护：分层来保护数据安全
> * 可靠性/持久性：保持文件的持久即使发生崩溃、媒体错误、攻击等

> 文件属性：名称，类型，位置，大小，，，
>
> 文件头



> 文件描述符
>
> 文件使用模式：使用程序必须在使用前先”打开“文件
>
> 内核跟踪每个进程打开的文件
>
> 需要元数据来管理打开文件
>
> * 文件指针：指向最近的一次读写位置
> * 文件打开计数：记录文件打开次数
> * 文件磁盘位置：缓存数据访问信息
> * 访问权限：每个程序访问模式信息
>
> 用户视图：持久的**数据结构**
>
> 系统访问接口：**字节**的集合
>
> **在文件系统中的所有操作都是在整个快空间上进行的**
>
> 用户访问文件的模式：
>
> * **顺序访问**：按字节依次读取
> * **随机访问**：从中间读写
> * **基于内容访问**：通过特征
>
> 文件内部结构
>
> * 无结构：单词、比特的队列
> * 简单记录结构：列、固定长度、可变长度
> * 复杂结构：格式化文件、可执行文件
>
> **多用户系统**中的文件共享是必要的



> 目录
>
> 文件以目录的方式组织起来
>
> 目录是一类特殊的文件：每个目录都包含一张表
>
> 目录和文件的树型结构，层次名称空间
>
> os应该只允许内核模式修改目录：确保映射的完整性；应用程序能够读目录
>
> 存储目录中的文件
>
> * 文件名的线性列表，包含了指向数据块的指针：编程简单，执行耗时
> * hash表，hash数据结构的线性表：减少目录搜索时间；碰撞（两个文件名hash值相同）；固定大小
>
> 名字解析：逻辑名字转换为物理资源的过程
>
> 一个文件系统需要先**挂载**才能访问
>
> 一个未被挂载的文件系统被挂载在**挂载点**上



> 文件别名：两个或多个文件名关联同一个文件
>
> 链接方式：
>
> * 硬链接：多个文件项指向一个文件
> * 软连接：以“快捷方式”指向其他文件
>
> 通过存储真实文件的逻辑名来实现
>
> 删除有别名的文件：别名将成为“悬空指针”
>
> 目录和文件的管理：backpointers方案
>
> * 每个文件有一个包含多个backpointers的列表
> * backpointers使用菊花链管理
>
> 可能存在文件指向循环，如何避免：
>
> * 只允许到文件的链接，不允许在子目录的链接
> * 每增加一个新的链接都有循环检测算法缺点是否合理
> * 限制路径可遍历文件目录的数量



> 文件系统种类分为：
>
> * 磁盘文件系统：文件存储在数据存储设备（磁盘等）上
> * 数据库文件系统：文件根据其特征是可被寻址的
> * 日志文件系统：记录文件系统的修改/事件
> * 网络/分布式文件系统
> * 特殊/虚拟文件系统
>
> 文件可以通过网络被共享
>
> * 文件位于远程服务器
> * 客户端远程挂载服务器文件系统
> * 标准系统文件访问被转换成远程访问
> * 标准文件共享协议：NFS for Linux； CIFS for Windows
>
> 分布式文件系统的问题：
>
> * 客户端和客户端上的用户辨别起来很复杂
> * NFS不安全
> * 一致性问题
> * 错误处理模式



### 7.2 文件操作

> 虚拟文件系统
>
> 虚拟文件系统的分层结构
>
> * 上层：虚拟（逻辑）文件系统
> * 底层（特定文件系统模块）
>
> 目的：对所有不同文件系统的抽象
>
> 功能：
>
> * 提供相同的文件和文件相同的接口
> * 管理所有文件和文件系统关联的数据结构
> * 高校查询例程，遍历文件系统
> * 与特定文件系统模块的交互
>
> 基本文件系统数据结构包括：
>
> * 卷控制块（每个文件系统一个）
> * 文件控制块（每个文件一个）
> * 目录结点（每个目录项一个）
>
> 位置：持续存储在二级存储中
>
> 当需要加载进内存：
>
> * 卷控制块：当文件系统挂载时进入内存
> * 文件控制块：当文件被访问时进入每次
> * 目录结点：在遍历一个文件路径时进入内存



> 数据块缓存
>
> 数据块按需读入内存：
>
> * 提供read( )操作
> * 预读：预选读取后面数据块
>
> 数据块使用后被缓存
>
> * 假设数据会再次使用
> * 写操作可能被缓存和延迟写入
>
> 两种数据块缓存方式
>
> * 普通缓冲区缓存
> * 页缓存：统一缓存数据块和内存页
>
> 分页缓存（）：
>
> * 分页要求：当需要一个页时才将其载入内存
> * 支持存储
> * 文件数据块的页缓存
> * * 在虚拟内存中的文件数据块被映射成页
>   * 文件读/写操作被转换成对内存的访问
>   * 可能导致缺页和/或设置为脏页



> 打开文件的数据结构
>
> 打开文件描述：
>
> * 每个被打开的文件一个
> * 文件状态信息
> * 目录项，当前文件指针，文件操作设置等
>
> 打开文件表
>
> * 一个进程
> * 一个系统级
> * 每个卷控制块会保存一个列表
> * 所有如果文件被打开将不能被卸载
>
> 强制：根据锁保持情况和需求拒绝访问
>
> 劝告：进程可以查询锁的状态来决定怎么做



> 文件分配
>
> 分配方式|
>
> * 连续分配
> * 链式分配
> * 索引分配
>
> 指标：
>
> * 高效：存储利用
> * 表现：访问速度
>
> | 分配方式 | 内容                                                         | 位置/分配策略          | 优势                                           | 不足                                                         |
> | -------- | ------------------------------------------------------------ | ---------------------- | ---------------------------------------------- | ------------------------------------------------------------ |
> | 连续分配 | 文件头指定起始块和长度                                       | 最先匹配，最佳匹配 ... | 文件读取表现好；高效的顺序和随机访问           | 碎片；文件增长问题                                           |
> | 链式分配 | 文件以数据块链表方式存储；文件头包含了到第一块和最后一块的指针 |                        | 创建、增大、缩小很容易；没有碎片               | 不可能进行真正的随机访问；可靠性差                           |
> | 索引分配 | 为每个文件创建一个名为索引数据块的非数据数据块；文件头包含了索引数据块 |                        | 创建、增大、缩小很容易；没有碎片；支持直接访问 | 当文件很小时，存储索引的开销大，大文件采用链式索引块，多级索引块 |



> 空闲空间列表
>
> 用位图代表空闲数据块列表：0为空闲的，1是已分配
>
> ![空闲](文件系统\空闲.png)



### 7.3 磁盘

> 通常磁盘通过分区来最大限度减小寻道时间
>
> * 一个分区是一个柱面的集合
> * 每个分区都是逻辑上独立的磁盘
>
> 分区：硬盘磁盘的一种适合os指定格式的划分
>
> 卷：一个拥有一个文件系统实例的可访问的存储空间
>
> 使用多个并行磁盘来增加
>
> * 吞吐量（通过并行）
> * 可靠性和可用性（通过冗余）
>
> RAID：冗余磁盘陈列：各种磁盘管理技术
>
> 实现:
>
> * 在os内核：存储/卷管理
> * RAID硬件控制器（I/O）
>
> 数据块分成多个子块，存储在独立的磁盘中
>
> 通过更大的有效块大小来提供更大的磁盘带宽



